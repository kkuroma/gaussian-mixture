\section*{Preface}
We aim to establish the mathematical derivations that will be use throughout the document here.
\begin{theorem}[MLE of Categorical Sampling]
    Given $y_1,y_2,\dots,y_n$ are sampled IID from $\{1,2,\dots,k\}$ such that $\p(y_i=j)=\phi_j$, $\sum_{j=1}^k=\phi_j$, the MLE for $\phi_i$ is given by
    \[
        \hat{\phi}_j = \frac{1}{n} \sum_{i=1}^n \mathbb{I}\{y_i=j\}
    \]
\end{theorem}
\begin{proof}
    The likelihood of the parameters $\phi_1,\phi_2,\dots,\phi_k$ given observations $y_1,y_2,\dots,y_n$ can be expressed as
    \[
    f(\phi_1,\phi_2,\dots,\phi_k) = \prod_{i=1}^n \phi_{y_i} = \prod_{j=1}^k \phi_{j} ^ {\frac{1}{n} \sum_{i=1}^n \mathbb{I}\{y_i=j\}}
    \]
    and consequently the log-likelihood
    \[
    g(\phi_1,\phi_2,\dots,\phi_k) = \frac{1}{n} \sum_{j=1}^k \log(\phi_{j}) \left(\sum_{i=1}^n \mathbb{I}\{y_i=j\}\right)
    \]
    we are able to solve for the MLE using Lagrangian multipliers. Consider the objective function 
    \[
    \mathcal{L}(\phi_1,\phi_2,\dots,\phi_k,\lambda) = \sum_{j=1}^k \log(\phi_{j}) \left(\sum_{i=1}^n \mathbb{I}\{y_i=j\}\right) + \lambda\left(1-\sum_{j=1}^k\phi_j\right)
    \]
    Taking the partial derivative for the gradient
    \[
    \frac{\partial}{\partial \phi_l} \mathcal{L}(\phi_1,\phi_2,\dots,\phi_k,\lambda) = \frac{\sum_{i=1}^n \mathbb{I}\{y_i=l\}}{\phi_l} - \lambda
    \]
    and the second partial derivative for the hessian
    \[
        \frac{\partial^2}{\partial \phi_l^2} \mathcal{L}(\phi_1,\phi_2,\dots,\phi_k,\lambda) = -\frac{\sum_{i=1}^n \mathbb{I}\{y_i=l\}}{\phi_l^2}
        \text{ and }
        \frac{\partial}{\partial \phi_l}\frac{\partial}{\partial \phi_m}\mathcal{L}(\phi_1,\phi_2,\dots,\phi_k,\lambda) = 0
    \]
    We can see that the hessian is negative semi-definite, meaning setting the gradient as $\mathbf{0}$ or equivalently $\phi_l=\frac{\sum_{i=1}^n \mathbb{I}\{y_i=l\}}{\lambda}$ yields the maximum. Since
    \[
        1 = \sum_{j=1}^k\phi_j = \sum_{j=1}^k \frac{\sum_{i=1}^n \mathbb{I}\{y_i=j\}}{\lambda} = \frac{n}{\lambda}
    \]
    therefore, $\lambda=n$. Put together, the empirical prediction $\hat{\phi_j} = \frac{\sum_{i=1}^n \mathbb{I}\{y_i=j\}}{n}$ is the MLE, completing the proof
\end{proof}

\begin{theorem}[MLE of Multivariate Gaussian]
    Given $\mathbf{x}_1,\mathbf{x}_2,\dots,\mathbf{x}_n\in\R^d$ are sampled IID from $\normal(\boldsymbol{\mu},\Sigma)$, the MLE for $\boldsymbol{\mu}$ and $\Sigma$ are given by
    \[ 
        \boldsymbol{\mu} = \frac{1}{n} \sum_{i=1}^n \mathbf{x}_i \text{ and } \Sigma = \frac{1}{n} \sum_{i=1}^n \mathbf{x}_i \mathbf{x}_i^\top
    \]
\end{theorem}
\begin{proof}
    The likelihood of the parameters $\boldsymbol{\mu}$ and $\Sigma$ given observations $\mathbf{x}_1,\mathbf{x}_2,\dots,\mathbf{x}_n$ can be expressed as
    \[
    f(\boldsymbol{\mu},\Sigma) = \prod_{i=1}^n \frac{1}{(2\pi)^{d/2}|\Sigma|^{1/2}} \exp\left( -\frac{1}{2} (\mathbf{x}_i - \boldsymbol{\mu})^\top \Sigma^{-1} (\mathbf{x}_i - \boldsymbol{\mu}) \right)
    \]
    and consequently the log-likelihood
    \[
    g(\boldsymbol{\mu},\Sigma) = -\frac{n}{2} \log |\Sigma| - \frac{nd}{2} \log(2\pi) - \frac{1}{2} \sum_{i=1}^n (\mathbf{x}_i - \boldsymbol{\mu})^\top \Sigma^{-1} (\mathbf{x}_i - \boldsymbol{\mu})
    \]
    To find the MLE, we maximize $g(\boldsymbol{\mu},\Sigma)$ with respect to $\boldsymbol{\mu}$ and $\Sigma$. First, optimizing with respect to $\boldsymbol{\mu}$, we take the gradient and hessian
    \[
    \frac{\partial}{\partial \boldsymbol{\mu}} g(\boldsymbol{\mu},\Sigma) = \Sigma^{-1} \sum_{i=1}^n (\mathbf{x}_i - \boldsymbol{\mu})
    \text{ and }
    \frac{\partial^2}{\partial \boldsymbol{\mu}^2} g(\boldsymbol{\mu},\Sigma) = -\Sigma^{-1}
    \]
    Since $\Sigma$ has to be positive semi-definite to be a covariance, so does $\Sigma^{-1}$, which implies the gradient to zero or
    \[
    \Sigma^{-1} \sum_{i=1}^n (\mathbf{x}_i - \boldsymbol{\mu}) = 0
    \implies
    \sum_{i=1}^n (\mathbf{x}_i - \boldsymbol{\mu}) = 0
    \implies
    n\boldsymbol{\mu} = \sum_{i=1}^n \mathbf{x}_i
    \implies
    \boldsymbol{\mu} = \frac{1}{n} \sum_{i=1}^n \mathbf{x}_i
    \]
    yields the maximum. Next, optimizing with respect to $\Sigma$, plugging $\hat{\boldsymbol{\mu}}$ back in, the log-likelihood simplifies to
    \[
    g(\boldsymbol{\mu},\Sigma) = -\frac{n}{2} \log |\Sigma| - \frac{1}{2} \sum_{i=1}^n (\mathbf{x}_i - \hat{\boldsymbol{\mu}})^\top \Sigma^{-1} (\mathbf{x}_i - \hat{\boldsymbol{\mu}})
    \]
    Here, we use the trace trick:
    \[
    -\frac{n}{2} \log |\Sigma| - \frac{1}{2} \sum_{i=1}^n \text{Tr}\left((\mathbf{x}_i - \hat{\boldsymbol{\mu}})^\top \Sigma^{-1} (\mathbf{x}_i - \hat{\boldsymbol{\mu}})\right)
    \]
    Taking the derivative with respect to $\Sigma^{-1}$ using the these identities
    \[
    \frac{\partial}{\partial \Sigma^{-1}} \log |\Sigma| = \Sigma
    \quad \text{and} \quad
    \frac{\partial}{\partial \Sigma^{-1}} \operatorname{tr}(A\Sigma^{-1}) = -A
    \]
    we obtain
    \[
    \frac{\partial}{\partial \Sigma^{-1}} g(\boldsymbol{\mu},\Sigma) = \frac{n}{2}\Sigma - \frac{1}{2}\sum_{i=1}^n (\mathbf{x}_i - \hat{\boldsymbol{\mu}})(\mathbf{x}_i - \hat{\boldsymbol{\mu}})^\top
    \]
    Setting the gradient to zero, we get
    \[
    n\Sigma = \sum_{i=1}^n (\mathbf{x}_i - \hat{\boldsymbol{\mu}})(\mathbf{x}_i - \hat{\boldsymbol{\mu}})^\top
    \implies
    \Sigma = \frac{1}{n} \sum_{i=1}^n (\mathbf{x}_i - \hat{\boldsymbol{\mu}})(\mathbf{x}_i - \hat{\boldsymbol{\mu}})^\top
    \]
    Put together, the empirical predictions are indeed the MLE, thus completing the proof.
\end{proof}

\begin{definition}[Kullback–Leibler (KL) Divergence]
    The Kullback–Leibler (KL) divergence between two probability distributions $p$ and $q$ over a continuous domain is defined as
    \[
    \mathrm{KL}(p\|q) = \mathbb{E}_{\mathbf{x}\sim p} \left[ \log p(\mathbf{x}) - \log q(\mathbf{x}) \right] = \int p(\mathbf{x}) \log\left( \frac{p(\mathbf{x})}{q(\mathbf{x})} \right) \, d\mathbf{x}
    \]
    It measures the extent to which the distribution $p$ differs from the distribution $q$. It's called a divergence as $\mathrm{KL}(p\|q)$ and $\mathrm{KL}(q\|p)$ are not necessarily equal.
\end{definition}

\begin{theorem}[KL Divergence of Multivariate Gaussians]
    Given two multivariate Gaussian distributions $p=\mathcal{N}(\boldsymbol{\mu}_p,\Sigma_p)$ and $q=\mathcal{N}(\boldsymbol{\mu}_q,\Sigma_q)$, the KL divergence between them is
    \[
    \mathrm{KL}(p\|q) = \frac{1}{2} \left( \log\frac{|\Sigma_q|}{|\Sigma_p|} - d + \operatorname{Tr}(\Sigma_q^{-1}\Sigma_p) + (\boldsymbol{\mu}_q - \boldsymbol{\mu}_p)^\top \Sigma_q^{-1} (\boldsymbol{\mu}_q - \boldsymbol{\mu}_p) \right)
    \]
\end{theorem}

\begin{proof}
    By definition, the KL divergence is
    \[
    \mathrm{KL}(p\|q) = \mathbb{E}_{\mathbf{x}\sim p} \left[ \log p(\mathbf{x}) - \log q(\mathbf{x}) \right]
    \]
    Using the density of a multivariate Gaussian, we have
    \[
    \log p(\mathbf{x}) = -\frac{d}{2}\log(2\pi) - \frac{1}{2}\log|\Sigma_p| - \frac{1}{2} (\mathbf{x} - \boldsymbol{\mu}_p)^\top \Sigma_p^{-1} (\mathbf{x} - \boldsymbol{\mu}_p)
    \]
    and
    \[
    \log q(\mathbf{x}) = -\frac{d}{2}\log(2\pi) - \frac{1}{2}\log|\Sigma_q| - \frac{1}{2} (\mathbf{x} - \boldsymbol{\mu}_q)^\top \Sigma_q^{-1} (\mathbf{x} - \boldsymbol{\mu}_q)
    \]
    Substituting into the KL formula, the constant $-\frac{d}{2}\log(2\pi)$ cancels out, giving
    \[
    \mathrm{KL}(p\|q) = \mathbb{E}_{\mathbf{x}\sim p} \left[ -\frac{1}{2}\log|\Sigma_p| + \frac{1}{2}\log|\Sigma_q| -\frac{1}{2} (\mathbf{x} - \boldsymbol{\mu}_p)^\top \Sigma_p^{-1} (\mathbf{x} - \boldsymbol{\mu}_p) + \frac{1}{2} (\mathbf{x} - \boldsymbol{\mu}_q)^\top \Sigma_q^{-1} (\mathbf{x} - \boldsymbol{\mu}_q) \right]
    \]
    Grouping constants:
    \[
    \mathrm{KL}(p\|q) = \frac{1}{2} \left( \log\frac{|\Sigma_q|}{|\Sigma_p|} + \mathbb{E}_{\mathbf{x}\sim p}\left[ (\mathbf{x} - \boldsymbol{\mu}_q)^\top \Sigma_q^{-1} (\mathbf{x} - \boldsymbol{\mu}_q) - (\mathbf{x} - \boldsymbol{\mu}_p)^\top \Sigma_p^{-1} (\mathbf{x} - \boldsymbol{\mu}_p) \right] \right)
    \]
    Now, expand each quadratic form separately. First,
    \[
    (\mathbf{x} - \boldsymbol{\mu}_q)^\top \Sigma_q^{-1} (\mathbf{x} - \boldsymbol{\mu}_q) = (\mathbf{x} - \boldsymbol{\mu}_p + \boldsymbol{\mu}_p - \boldsymbol{\mu}_q)^\top \Sigma_q^{-1} (\mathbf{x} - \boldsymbol{\mu}_p + \boldsymbol{\mu}_p - \boldsymbol{\mu}_q)
    \]
    Expanding the square,
    \[
    = (\mathbf{x} - \boldsymbol{\mu}_p)^\top \Sigma_q^{-1} (\mathbf{x} - \boldsymbol{\mu}_p) + 2(\mathbf{x} - \boldsymbol{\mu}_p)^\top \Sigma_q^{-1} (\boldsymbol{\mu}_p - \boldsymbol{\mu}_q) + (\boldsymbol{\mu}_p - \boldsymbol{\mu}_q)^\top \Sigma_q^{-1} (\boldsymbol{\mu}_p - \boldsymbol{\mu}_q)
    \]
    Taking expectation under $\mathbf{x}\sim p$, and using that $\mathbb{E}[\mathbf{x}] = \boldsymbol{\mu}_p$ and $\mathbb{E}[(\mathbf{x} - \boldsymbol{\mu}_p)(\mathbf{x} - \boldsymbol{\mu}_p)^\top] = \Sigma_p$, we get
    \[
    \mathbb{E}\left[ (\mathbf{x} - \boldsymbol{\mu}_p)^\top \Sigma_q^{-1} (\mathbf{x} - \boldsymbol{\mu}_p) \right] = \operatorname{Tr}(\Sigma_q^{-1} \Sigma_p)
    \]
    and
    \[
    \mathbb{E}\left[ 2(\mathbf{x} - \boldsymbol{\mu}_p)^\top \Sigma_q^{-1} (\boldsymbol{\mu}_p - \boldsymbol{\mu}_q) \right] = 0
    \]
    because the expectation of $\mathbf{x}-\boldsymbol{\mu}_p$ is zero. The third term is constant and remains
    \[
    (\boldsymbol{\mu}_p - \boldsymbol{\mu}_q)^\top \Sigma_q^{-1} (\boldsymbol{\mu}_p - \boldsymbol{\mu}_q)
    \]
    Similarly, for the second expectation
    \[
    \mathbb{E}\left[ (\mathbf{x} - \boldsymbol{\mu}_p)^\top \Sigma_p^{-1} (\mathbf{x} - \boldsymbol{\mu}_p) \right] = \operatorname{Tr}(\Sigma_p^{-1} \Sigma_p) = d
    \]
    Putting everything together:
    \[
    \mathrm{KL}(p\|q) = \frac{1}{2} \left( \log\frac{|\Sigma_q|}{|\Sigma_p|} - d + \operatorname{Tr}(\Sigma_q^{-1}\Sigma_p) + (\boldsymbol{\mu}_q - \boldsymbol{\mu}_p)^\top \Sigma_q^{-1} (\boldsymbol{\mu}_q - \boldsymbol{\mu}_p) \right)
    \]
    thus completing the proof.
\end{proof}